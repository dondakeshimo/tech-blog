<!DOCTYPE html><html lang="ja"><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png"/><link rel="manifest" href="/favicon/site.webmanifest"/><link rel="mask-icon" href="/favicon/safari-pinned-tab.svg" color="#000000"/><link rel="shortcut icon" href="/favicon/favicon.ico"/><meta name="msapplication-TileColor" content="#fdf6e3"/><meta name="msapplication-config" content="/favicon/browserconfig.xml"/><meta name="theme-color" content="#fdf6e3"/><link rel="alternate" type="application/rss+xml" href="/feed.xml"/><meta name="description"/><meta property="og:title" content="機械学習の勉強を始めました"/><meta property="og:type" content="website"/><meta property="og:url" content="{DOMAIN}/posts/2017-08-19-intro_deep_learning"/><meta property="og:description"/><meta property="og:image" content="https://og-image.vercel.app/Next.js%20Blog%20Starter%20Example.png?theme=light&amp;md=1&amp;fontSize=100px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fnextjs-black-logo.svg"/><meta property="og:image:alt"/><meta property="og:site_name" content="dondakeshimoの丸太"/><meta property="og:locale" content="ja_JP"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:title" content="機械学習の勉強を始めました"/><meta property="twitter:description"/><meta property="twitter:image" content="https://og-image.vercel.app/Next.js%20Blog%20Starter%20Example.png?theme=light&amp;md=1&amp;fontSize=100px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fnextjs-black-logo.svg"/><meta property="twitter:image:alt"/><meta property="twitter:site" content="dondakeshimo"/><meta property="twitter:creator" content="dondakeshimo"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous"/><title>機械学習の勉強を始めました | dondakeshimoの丸太</title><meta property="og:image" content="/assets/blog/dynamic-routing/cover.jpg"/><meta name="next-head-count" content="31"/><link rel="preload" href="/_next/static/css/0f9d9436e0b0760d86ae.css" as="style"/><link rel="stylesheet" href="/_next/static/css/0f9d9436e0b0760d86ae.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-a54b4f32bdc1ef890ddd.js"></script><script src="/_next/static/chunks/webpack-61095c13c5984b221292.js" defer=""></script><script src="/_next/static/chunks/framework-2191d16384373197bc0a.js" defer=""></script><script src="/_next/static/chunks/main-c034215587cd157b2989.js" defer=""></script><script src="/_next/static/chunks/pages/_app-d2622b3552023a29a89a.js" defer=""></script><script src="/_next/static/chunks/cb1608f2-854db26f8877d6c8528f.js" defer=""></script><script src="/_next/static/chunks/a9a7754c-ecd5c258dd80f13aa656.js" defer=""></script><script src="/_next/static/chunks/349-e0275456508bca40c658.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bslug%5D-c414199f8f835e5668ae.js" defer=""></script><script src="/_next/static/yNrEyh5A0Oyk3eJQw5kY9/_buildManifest.js" defer=""></script><script src="/_next/static/yNrEyh5A0Oyk3eJQw5kY9/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="min-h-vfull"><main><div class="full-container mx-auto px-5"><a class="text-l font-bold text-tight mb-xl mt-l"><a class="logo" href="/"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="hand-point-up" class="svg-inline--fa fa-hand-point-up fa-w-12 svg-l dondake-icon" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M135.652 0c23.625 0 43.826 20.65 43.826 44.8v99.851c17.048-16.34 49.766-18.346 70.944 6.299 22.829-14.288 53.017-2.147 62.315 16.45C361.878 158.426 384 189.346 384 240c0 2.746-.203 13.276-.195 16 .168 61.971-31.065 76.894-38.315 123.731C343.683 391.404 333.599 400 321.786 400H150.261l-.001-.002c-18.366-.011-35.889-10.607-43.845-28.464C93.421 342.648 57.377 276.122 29.092 264 10.897 256.203.008 242.616 0 224c-.014-34.222 35.098-57.752 66.908-44.119 8.359 3.583 16.67 8.312 24.918 14.153V44.8c0-23.45 20.543-44.8 43.826-44.8zM136 416h192c13.255 0 24 10.745 24 24v48c0 13.255-10.745 24-24 24H136c-13.255 0-24-10.745-24-24v-48c0-13.255 10.745-24 24-24zm168 28c-11.046 0-20 8.954-20 20s8.954 20 20 20 20-8.954 20-20-8.954-20-20-20z"></path></svg>dondakeshimoの丸太</a></a><article class="mb-2xl"><h1 class="title text-xl font-bold mb-l text-center">機械学習の勉強を始めました</h1><div class="container-80 mx-auto"><div class="mb-l text-l"><time dateTime="2017-08-19">August	19, 2017</time></div></div><div class="container-80 mx-auto"><div><h1 id="目次">目次</h1>
<ul>
<li><a href="#%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%AE%E5%8B%89%E5%BC%B7%E3%82%92%E7%9C%9F%E9%9D%A2%E7%9B%AE%E3%81%AB%E3%81%AF%E3%81%98%E3%82%81%E3%81%BE%E3%81%97%E3%81%9F%E3%80%82">機械学習の勉強を真面目にはじめました。</a></li>
<li><a href="#%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF">ニューラルネットワーク</a>
<ul>
<li>
<ul>
<li><a href="#%E5%85%A5%E5%8A%9B%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E6%A7%8B%E9%80%A0">入力ネットワークの構造</a></li>
<li><a href="#%E6%B4%BB%E6%80%A7%E5%8C%96%E9%96%A2%E6%95%B0">活性化関数</a></li>
<li><a href="#%E3%83%90%E3%83%83%E3%83%81%E5%87%A6%E7%90%86">バッチ処理</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AE%E5%AD%A6%E7%BF%92">データの学習</a>
<ul>
<li>
<ul>
<li><a href="#%E6%90%8D%E5%A4%B1%E9%96%A2%E6%95%B0">損失関数</a></li>
<li><a href="#%E5%8B%BE%E9%85%8D%E6%B3%95">勾配法</a></li>
<li><a href="#%E3%81%93%E3%81%93%E3%81%BE%E3%81%A7%E3%81%AE%E3%81%BE%E3%81%A8%E3%82%81">ここまでのまとめ</a></li>
<li><a href="#%E9%81%8E%E5%AD%A6%E7%BF%92">過学習</a></li>
</ul>
</li>
<li><a href="#%E8%AA%A4%E5%B7%AE%E9%80%86%E4%BC%9D%E6%92%ADbackpropagation">誤差逆伝播(backpropagation)</a>
<ul>
<li>
<ul>
<li><a href="#%E5%8B%BE%E9%85%8D%E7%A2%BA%E8%AA%8D">勾配確認</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E6%9C%80%E9%81%A9%E5%8C%96%E6%89%8B%E6%B3%95">最適化手法</a>
<ul>
<li>
<ul>
<li>
<ul>
<li><a href="#sgd">SGD</a></li>
<li><a href="#momentum">Momentum</a></li>
<li><a href="#adagrad">AdaGrad</a></li>
<li><a href="#adam">Adam</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E9%87%8D%E3%81%BF%E3%81%AE%E5%88%9D%E6%9C%9F%E5%80%A4">重みの初期値</a>
<ul>
<li>
<ul>
<li><a href="#1%E3%82%92%E6%A8%99%E6%BA%96%E5%81%8F%E5%B7%AE%E3%81%A8%E3%81%97%E3%81%9F%E3%82%AC%E3%82%A6%E3%82%B9%E5%88%86%E5%B8%83">1を標準偏差としたガウス分布</a></li>
<li><a href="#0001%E3%82%92%E6%A8%99%E6%BA%96%E5%81%8F%E5%B7%AE%E3%81%A8%E3%81%97%E3%81%9F%E3%82%AC%E3%82%A6%E3%82%B9%E5%88%86%E5%B8%83">0.001を標準偏差としたガウス分布</a></li>
<li><a href="#xavier%E3%81%AE%E5%88%9D%E6%9C%9F%E5%80%A4">Xavierの初期値</a></li>
<li><a href="#he%E3%81%AE%E5%88%9D%E6%9C%9F%E5%80%A4">Heの初期値</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#batch-normalization">Batch Normalization</a></li>
<li><a href="#%E6%AD%A3%E5%89%87%E5%8C%96">正則化</a>
<ul>
<li>
<ul>
<li><a href="#weight-decay%E8%8D%B7%E9%87%8D%E6%B8%9B%E8%A1%B0">Weight decay(荷重減衰)</a></li>
<li><a href="#dropout">Dropout</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AFcnn">畳み込みニューラルネットワーク(CNN)</a>
<ul>
<li>
<ul>
<li><a href="#convolution%E3%83%AC%E3%82%A4%E3%83%A4">Convolutionレイヤ</a></li>
<li><a href="#pooling%E3%83%AC%E3%82%A4%E3%83%A4">Poolingレイヤ</a></li>
<li><a href="#cnn%E3%81%AE%E7%89%B9%E5%BE%B4%EF%BC%9F">CNNの特徴？</a></li>
<li><a href="#%E4%BB%A3%E8%A1%A8%E7%9A%84%E3%81%AAcnn">代表的なCNN</a>
<ul>
<li>
<ul>
<li><a href="#lenet">LeNet</a></li>
<li><a href="#alexnet">AlexNet</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0">ディープラーニング</a>
<ul>
<li>
<ul>
<li><a href="#%E5%B1%A4%E3%82%92%E5%8E%9A%E3%81%8F%E3%81%99%E3%82%8B%E3%81%A8%E8%A8%80%E3%81%86%E3%81%93%E3%81%A8">層を厚くすると言うこと</a></li>
<li><a href="#%E6%9C%89%E5%90%8D%E3%81%AA%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF">有名なネットワーク</a>
<ul>
<li>
<ul>
<li><a href="#vgg">VGG</a></li>
<li><a href="#googlelenet">GoogleLeNet</a></li>
<li><a href="#resnet">ResNet</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E8%BB%A2%E7%A7%BB%E5%AD%A6%E7%BF%92">転移学習</a></li>
<li><a href="#%E6%9C%80%E8%BF%91%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%81%A7%E8%A1%8C%E3%82%8F%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E3%81%93%E3%81%A8">最近ディープラーニングで行われていること</a></li>
<li><a href="#%E5%BC%B7%E5%8C%96%E5%AD%A6%E7%BF%92">強化学習</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E3%81%BE%E3%81%A8%E3%82%81">まとめ</a></li>
</ul>
<h1 id="機械学習の勉強を真面目にはじめました。">機械学習の勉強を真面目にはじめました。</h1>
<p>今回しっかりと基礎から見直そうと思い、入門書を精読することにしました。
具体的には上記の本を精読し、しっかりとゼロから作っていこうかと。
なんとなく難しかったところとかを適当にまとめたり、シンプルにようやくしたりします。</p>
<h1 id="ニューラルネットワーク">ニューラルネットワーク</h1>
<h3 id="入力ネットワークの構造">入力ネットワークの構造</h3>
<p>入力層、隠れ層、出力層に分けられる。
入力層は例えば、28x28の画像であれば、28x28=784の入力。
隠れ層は何層重ねてもよく、さらにどれだけ縮小しても拡大しても良い。
出力層はクラス分類問題であれば、クラスの数となる。
行列計算と非常に相性が良い構造である。</p>
<h3 id="活性化関数">活性化関数</h3>
<ul>
<li>シグモイド関数</li>
<li>ステップ関数</li>
<li>ReLU関数</li>
<li>ソフトマックス関数</li>
<li>恒等関数</li>
</ul>
<p>これらを回帰問題か分類問題かなどに応じて使い分ける。
主に、重みを付与しながらの層から層への情報伝播の後、
各層で行われる処理はこのような関数による変換。</p>
<h3 id="バッチ処理">バッチ処理</h3>
<p>一回に入力する量を増やす処理。
画像であれば、何枚もの画像を別次元に格納する。
この処理により高速化の恩恵が得られる。</p>
<h1 id="データの学習">データの学習</h1>
<h3 id="損失関数">損失関数</h3>
<p>損失関数とは機械学習における目標値である。
損失関数から出力される値を最小化することを目標に機械は学習を行う。
主に用いられる関数として下記のものがあげられる。</p>
<ul>
<li>二乗和誤差</li>
<li>交差エントロピー誤差</li>
</ul>
<h3 id="勾配法">勾配法</h3>
<p>極小値にハマり学習の進まないプラトーという状況に陥ることに注意。
毎回の学習の更新量を定めるパラメタを <strong>学習率</strong> と呼ぶ。
学習率は人間があらかじめ設定する必要があるため <strong>ハイパーパラメタ</strong>
と呼ばれる。</p>
<h3 id="ここまでのまとめ">ここまでのまとめ</h3>
<p>まとめてみると学習の流れは</p>
<ol>
<li>ミニバッチ</li>
<li>勾配の算出</li>
<li>パラメタの更新</li>
</ol>
<p>これらを繰り返すことになる。この流れを確率的勾配降下法と呼ぶ。
また、ミニパッチ一回分の繰り返しを <strong>1epoch</strong> と呼ぶ</p>
<h3 id="過学習">過学習</h3>
<p>学習に用いたデータセットに特化した学習を行ってしまい汎化能力が失われた状態。
この状態を避けるために学習データとテストデータを分け、
定期的にテストデータの認識精度も測ることで、
両方の認識精度が向上していることを確認する必要がある。</p>
<h2 id="誤差逆伝播backpropagation">誤差逆伝播(backpropagation)</h2>
<p>微分値によってパラメタを進める方向、量を決めるが、
微分は一般的に重たい計算のため、高速化するために誤差逆伝播法を用いる。
これは各計算を分解、独立化し、chain ruleによって、
独立した計算それぞれに対する微分を考えていくことで、
行列計算として微分計算を行えると言う利点がある。
隠れ層での行列の形状を変化させる計算をAffineレイヤと呼び、
Affineレイヤを含む、上記の活性化関数それぞれに対し、
独立して計算済みのレイヤを実装していくことで、
部品を組み立てるようにニューラルネットワークを実装することができ、
かつ高速に微分計算を行うことができる。</p>
<h4 id="勾配確認">勾配確認</h4>
<p>実装の難しい誤差逆伝播法のバリデーションのため、
実装の簡単な数値微分の結果と比較すること。</p>
<h2 id="最適化手法">最適化手法</h2>
<p>パラメタの更新のことを最適化と呼ぶ。</p>
<ul>
<li>確率的勾配降下法(SGD)</li>
<li>Momentum</li>
<li>AdaGrad</li>
<li>Adam</li>
</ul>
<p>上記の4つをこの書籍では取り上げていた。</p>
<h5 id="sgd">SGD</h5>
<p>最もシンプルな手法。
勾配に学習率をかけたものを次のパラメタ更新に用いる。
欠点として、最小値までの傾斜が等方的でない場合、
ジグザグな動きをすることとなり、学習スピードが遅くなる。</p>
<h5 id="momentum">Momentum</h5>
<p>前回の学習スピードを保持することで、
同じ方向に進むときは加速度的に進み、
ジグザグな動きをするときはSGDと比べて減速するようにした。</p>
<h5 id="adagrad">AdaGrad</h5>
<p>学習率を定数ではなく変数にする。
過去全ての更新量を記憶し、そのぶん学習率を小さくしていく。
欠点として、学習に長時間かかった場合、学習率が0に近づき、
学習が進まなくなることが挙げられるが、それを改善したRMSProp
と言う手法も存在する。</p>
<h5 id="adam">Adam</h5>
<p>直感的にはMomentumとAdaGradを組み合わせたようなものらしい</p>
<h3 id="重みの初期値">重みの初期値</h3>
<h5 id="1を標準偏差としたガウス分布">1を標準偏差としたガウス分布</h5>
<p>0と1にアクティベーション(各レイヤの出力)が固まることから
勾配消失が起きているとわかる。</p>
<h5 id="0001を標準偏差としたガウス分布">0.001を標準偏差としたガウス分布</h5>
<p>0.5付近に固まるため、勾配消失は怒っていないが、
その代わり表現力が小さくなっている。
ある値にアクティベーションが集まると、
単一のレイヤで全てのレイヤを表現できてしまうと言う問題や、
学習が効率よくいかない問題が挙げられる。</p>
<h5 id="xavierの初期値">Xavierの初期値</h5>
<p>前層のノードの数に準じて初期値を小さくする手法。
活性化関数が線形関数(線形関数に近似される関数)の際に用いられる。</p>
<h5 id="heの初期値">Heの初期値</h5>
<p>Xavierに2倍の広がりをもたせたもの。
非線形関数に用いられる。</p>
<h3 id="batch-normalization">Batch Normalization</h3>
<p>データを綺麗な分布にならす手法。
Affineレイヤと活性化関数レイヤの間に
Batch Normalizationレイヤを入れて使用する。</p>
<ul>
<li>学習スピードの増加</li>
<li>初期値に対する依存度の減少</li>
<li>過学習の抑制</li>
</ul>
<p>などの効果がある。</p>
<h3 id="正則化">正則化</h3>
<p>過学習を抑制するための手法</p>
<h5 id="weight-decay荷重減衰">Weight decay(荷重減衰)</h5>
<p>損失関数に重みに準じた量を加算することで、
大きな重みを持つことにペナルティを課す。</p>
<h5 id="dropout">Dropout</h5>
<p>確率で、ノードを消去することで何かうまいこと過学習が抑制されるらしい。</p>
<h1 id="畳み込みニューラルネットワークcnn">畳み込みニューラルネットワーク(CNN)</h1>
<p>主に画像に用いられるニューラルネットワーク。
昔のモデル(ここまで考えてきたモデル)では、
Affineレイヤで前層の出力を全結合していたが、
その部分をConvolutionレイヤで置き換え、
必要に応じて、活性化関数適用後の出力にPoolingレイヤを挟むことで
Affineレイヤの形状無視と言う欠点を補う。</p>
<h3 id="convolutionレイヤ">Convolutionレイヤ</h3>
<p>形状を考えるために、入力データに対して、
<strong>フィルター(カーネル)</strong> を用いた結合を行う。
フィルターは入力データと同じチャンネル数で、任意のサイズを持つ。
フィルターのサイズと、
入力データに対する <strong>パティング</strong> 、フィルターの <strong>ストライド</strong> によって
出力データのサイズが決定する。
一つのフィルターに対して、出力データのチャンネル数は常に1つのため、
複数のフィルターを用意して、出力データのチャンネル数を調整する。</p>
<h3 id="poolingレイヤ">Poolingレイヤ</h3>
<p>サイズを小さくするための演算。
ある範囲の最も大きな値のみ抽出していくMaxPoolingが画像処理の分野では主流である。
Poolingレイヤの特徴は以下の3つに代表される。</p>
<ul>
<li>学習するパラメータがない</li>
<li>チャンネル数は変化しない</li>
<li>微小な位置変化に対してロバスト</li>
</ul>
<h3 id="cnnの特徴？">CNNの特徴？</h3>
<p>フィルターが前半の層では低次元のエッジなどを抽出していくのに対し、
後半のフィルターは高次元の犬の顔などを抽出し始めるらしい。
これは層を多くすることによって、出力までの下準備をそれまでのレイヤで
丹念にできることに起因するとかしないとか。</p>
<h3 id="代表的なcnn">代表的なCNN</h3>
<h5 id="lenet">LeNet</h5>
<p>1998年初めてのCNN？基本的な構造は今使われているものと同じだが、
PoolingレイヤでMaxPoolingを行なっているわけではないらしいのと、
活性化関数がSigmoid関数らしい。</p>
<h5 id="alexnet">AlexNet</h5>
<p>2012年に彗星のごとくコンペティションに現れ、
圧倒的な成績でトロフィーと話題をさらっていったAlexNetさんです。
機械学習ブームの火付け役をしてくれたらしいですね。LeNetと比べると</p>
<ul>
<li>活性化関数にReLU関数を用いる</li>
<li>LRNと言う局所的正規化を行う関数を挟む</li>
<li>Dropoutを使用する</li>
</ul>
<p>松尾教授の書籍を読んだ時、うろ覚えですが、確かこのDropoutが
革新的だったといっていたような気がします。うろ覚えなので突っ込まないでください。</p>
<h1 id="ディープラーニング">ディープラーニング</h1>
<h3 id="層を厚くすると言うこと">層を厚くすると言うこと</h3>
<ul>
<li>表現力の増加</li>
<li>表現するために必要な学習パラメタの減少</li>
<li>学習時間は増加</li>
</ul>
<p>こんな感じのメリットデメリットがあるらしい。
表現力の増加とあるが、実際、MNISTの認識では2層くらいのモデルが
最も高精度らしく、表現力がどの程度必要なのかも考えなければならない。
ちなみに2015年のクラス分類コンペティションの優勝モデルは
150層とか言う馬鹿げたレベルのディープさだったそうな。</p>
<h3 id="有名なネットワーク">有名なネットワーク</h3>
<h5 id="vgg">VGG</h5>
<p>CNNの基本型らしい。3x3の小さなフィルターでなんども畳み込むそうな。</p>
<h5 id="googlelenet">GoogleLeNet</h5>
<p>基本的に層をディープにするといったら、伝播方向っぽいんだけど、
Googleさんは横方向にも伸ばしてしまったそうな。
<strong>インセプション構造</strong> と呼ぶらしく、複数のサイズのフィルターで
たたみ込んでその結果を結合するそうな。</p>
<h5 id="resnet">ResNet</h5>
<p>GoogleがきてMSが来ないわけがない。
これがさっき言ったアホみたいに層を深くした150層ネットワーク。
レイヤを通した出力とレイヤを通す前の入力の合計をその層の出力とする
スキップ構造と呼ばれるものを用いることで、
勾配消失問題を克服して、層をものごっつ厚くできたそうな。</p>
<h3 id="転移学習">転移学習</h3>
<p>すでに学習済みのパラメタをそのまま初期値として用いて、
次の学習を行う手法のこと。少ないデータセットしか手元にない時とかいいらしい。</p>
<h3 id="最近ディープラーニングで行われていること">最近ディープラーニングで行われていること</h3>
<ul>
<li>物体検出(物体認識の適用範囲検索と物体認識の結合)</li>
<li>セグメンテーション(ピクセルレベルでのクラス分類)</li>
<li>画像キャプション生成(CNNとRNNの結合)</li>
<li>画像スタイル変換(中間出力とのloss)</li>
<li>画像生成(DCGAN)</li>
</ul>
<h3 id="強化学習">強化学習</h3>
<p>エージェント(computer)が環境から得られる報酬を
最大化するように動いていくのかな？
ゲームとかでやってるらしい。
パックマンをコンピューターにやらせたらもう人は勝てないらしい。
とりあえず強化学習にはまた独自のアルゴリズムがあるっぽくて(Q学習？)
それとCNNを融合させることでDeep Q-Networkとか言うすごい奴が生まれたらしい。</p>
<h1 id="まとめ">まとめ</h1>
<p>特殊な用語がたくさん出てきたので、
とりあえずこの分野に入るときには一回真面目に入門書を読むべきと感じました。</p></div></div></article></div></main></div><footer><div class="full-container mx-auto px-5"><div class="full-container mx-auto px-5"><div class="py-m sns-container my-l"><div class="mx-s github-icon"><a href="https://github.com/dondakeshimo"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" class="svg-inline--fa fa-github fa-w-16 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></div><div class="mx-s twitter-icon"><a href="https://twitter.com/dondakeshimo"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="twitter" class="svg-inline--fa fa-twitter fa-w-16 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a></div></div></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"機械学習の勉強を始めました","date":"2017-08-19","slug":"2017-08-19-intro_deep_learning","author":{"name":"JJ Kasper","picture":"/assets/blog/authors/jj.jpeg"},"content":"\u003ch1 id=\"目次\"\u003e目次\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%AE%E5%8B%89%E5%BC%B7%E3%82%92%E7%9C%9F%E9%9D%A2%E7%9B%AE%E3%81%AB%E3%81%AF%E3%81%98%E3%82%81%E3%81%BE%E3%81%97%E3%81%9F%E3%80%82\"\u003e機械学習の勉強を真面目にはじめました。\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF\"\u003eニューラルネットワーク\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#%E5%85%A5%E5%8A%9B%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E6%A7%8B%E9%80%A0\"\u003e入力ネットワークの構造\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E6%B4%BB%E6%80%A7%E5%8C%96%E9%96%A2%E6%95%B0\"\u003e活性化関数\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E3%83%90%E3%83%83%E3%83%81%E5%87%A6%E7%90%86\"\u003eバッチ処理\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AE%E5%AD%A6%E7%BF%92\"\u003eデータの学習\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#%E6%90%8D%E5%A4%B1%E9%96%A2%E6%95%B0\"\u003e損失関数\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E5%8B%BE%E9%85%8D%E6%B3%95\"\u003e勾配法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E3%81%93%E3%81%93%E3%81%BE%E3%81%A7%E3%81%AE%E3%81%BE%E3%81%A8%E3%82%81\"\u003eここまでのまとめ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E9%81%8E%E5%AD%A6%E7%BF%92\"\u003e過学習\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E8%AA%A4%E5%B7%AE%E9%80%86%E4%BC%9D%E6%92%ADbackpropagation\"\u003e誤差逆伝播(backpropagation)\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#%E5%8B%BE%E9%85%8D%E7%A2%BA%E8%AA%8D\"\u003e勾配確認\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E6%9C%80%E9%81%A9%E5%8C%96%E6%89%8B%E6%B3%95\"\u003e最適化手法\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#sgd\"\u003eSGD\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#momentum\"\u003eMomentum\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#adagrad\"\u003eAdaGrad\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#adam\"\u003eAdam\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E9%87%8D%E3%81%BF%E3%81%AE%E5%88%9D%E6%9C%9F%E5%80%A4\"\u003e重みの初期値\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#1%E3%82%92%E6%A8%99%E6%BA%96%E5%81%8F%E5%B7%AE%E3%81%A8%E3%81%97%E3%81%9F%E3%82%AC%E3%82%A6%E3%82%B9%E5%88%86%E5%B8%83\"\u003e1を標準偏差としたガウス分布\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#0001%E3%82%92%E6%A8%99%E6%BA%96%E5%81%8F%E5%B7%AE%E3%81%A8%E3%81%97%E3%81%9F%E3%82%AC%E3%82%A6%E3%82%B9%E5%88%86%E5%B8%83\"\u003e0.001を標準偏差としたガウス分布\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#xavier%E3%81%AE%E5%88%9D%E6%9C%9F%E5%80%A4\"\u003eXavierの初期値\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#he%E3%81%AE%E5%88%9D%E6%9C%9F%E5%80%A4\"\u003eHeの初期値\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#batch-normalization\"\u003eBatch Normalization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E6%AD%A3%E5%89%87%E5%8C%96\"\u003e正則化\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#weight-decay%E8%8D%B7%E9%87%8D%E6%B8%9B%E8%A1%B0\"\u003eWeight decay(荷重減衰)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#dropout\"\u003eDropout\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AFcnn\"\u003e畳み込みニューラルネットワーク(CNN)\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#convolution%E3%83%AC%E3%82%A4%E3%83%A4\"\u003eConvolutionレイヤ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#pooling%E3%83%AC%E3%82%A4%E3%83%A4\"\u003ePoolingレイヤ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#cnn%E3%81%AE%E7%89%B9%E5%BE%B4%EF%BC%9F\"\u003eCNNの特徴？\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E4%BB%A3%E8%A1%A8%E7%9A%84%E3%81%AAcnn\"\u003e代表的なCNN\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#lenet\"\u003eLeNet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#alexnet\"\u003eAlexNet\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0\"\u003eディープラーニング\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#%E5%B1%A4%E3%82%92%E5%8E%9A%E3%81%8F%E3%81%99%E3%82%8B%E3%81%A8%E8%A8%80%E3%81%86%E3%81%93%E3%81%A8\"\u003e層を厚くすると言うこと\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E6%9C%89%E5%90%8D%E3%81%AA%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF\"\u003e有名なネットワーク\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#vgg\"\u003eVGG\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#googlelenet\"\u003eGoogleLeNet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#resnet\"\u003eResNet\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E8%BB%A2%E7%A7%BB%E5%AD%A6%E7%BF%92\"\u003e転移学習\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E6%9C%80%E8%BF%91%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%81%A7%E8%A1%8C%E3%82%8F%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E3%81%93%E3%81%A8\"\u003e最近ディープラーニングで行われていること\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E5%BC%B7%E5%8C%96%E5%AD%A6%E7%BF%92\"\u003e強化学習\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E3%81%BE%E3%81%A8%E3%82%81\"\u003eまとめ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"機械学習の勉強を真面目にはじめました。\"\u003e機械学習の勉強を真面目にはじめました。\u003c/h1\u003e\n\u003cp\u003e今回しっかりと基礎から見直そうと思い、入門書を精読することにしました。\n具体的には上記の本を精読し、しっかりとゼロから作っていこうかと。\nなんとなく難しかったところとかを適当にまとめたり、シンプルにようやくしたりします。\u003c/p\u003e\n\u003ch1 id=\"ニューラルネットワーク\"\u003eニューラルネットワーク\u003c/h1\u003e\n\u003ch3 id=\"入力ネットワークの構造\"\u003e入力ネットワークの構造\u003c/h3\u003e\n\u003cp\u003e入力層、隠れ層、出力層に分けられる。\n入力層は例えば、28x28の画像であれば、28x28=784の入力。\n隠れ層は何層重ねてもよく、さらにどれだけ縮小しても拡大しても良い。\n出力層はクラス分類問題であれば、クラスの数となる。\n行列計算と非常に相性が良い構造である。\u003c/p\u003e\n\u003ch3 id=\"活性化関数\"\u003e活性化関数\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eシグモイド関数\u003c/li\u003e\n\u003cli\u003eステップ関数\u003c/li\u003e\n\u003cli\u003eReLU関数\u003c/li\u003e\n\u003cli\u003eソフトマックス関数\u003c/li\u003e\n\u003cli\u003e恒等関数\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eこれらを回帰問題か分類問題かなどに応じて使い分ける。\n主に、重みを付与しながらの層から層への情報伝播の後、\n各層で行われる処理はこのような関数による変換。\u003c/p\u003e\n\u003ch3 id=\"バッチ処理\"\u003eバッチ処理\u003c/h3\u003e\n\u003cp\u003e一回に入力する量を増やす処理。\n画像であれば、何枚もの画像を別次元に格納する。\nこの処理により高速化の恩恵が得られる。\u003c/p\u003e\n\u003ch1 id=\"データの学習\"\u003eデータの学習\u003c/h1\u003e\n\u003ch3 id=\"損失関数\"\u003e損失関数\u003c/h3\u003e\n\u003cp\u003e損失関数とは機械学習における目標値である。\n損失関数から出力される値を最小化することを目標に機械は学習を行う。\n主に用いられる関数として下記のものがあげられる。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e二乗和誤差\u003c/li\u003e\n\u003cli\u003e交差エントロピー誤差\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"勾配法\"\u003e勾配法\u003c/h3\u003e\n\u003cp\u003e極小値にハマり学習の進まないプラトーという状況に陥ることに注意。\n毎回の学習の更新量を定めるパラメタを \u003cstrong\u003e学習率\u003c/strong\u003e と呼ぶ。\n学習率は人間があらかじめ設定する必要があるため \u003cstrong\u003eハイパーパラメタ\u003c/strong\u003e\nと呼ばれる。\u003c/p\u003e\n\u003ch3 id=\"ここまでのまとめ\"\u003eここまでのまとめ\u003c/h3\u003e\n\u003cp\u003eまとめてみると学習の流れは\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eミニバッチ\u003c/li\u003e\n\u003cli\u003e勾配の算出\u003c/li\u003e\n\u003cli\u003eパラメタの更新\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eこれらを繰り返すことになる。この流れを確率的勾配降下法と呼ぶ。\nまた、ミニパッチ一回分の繰り返しを \u003cstrong\u003e1epoch\u003c/strong\u003e と呼ぶ\u003c/p\u003e\n\u003ch3 id=\"過学習\"\u003e過学習\u003c/h3\u003e\n\u003cp\u003e学習に用いたデータセットに特化した学習を行ってしまい汎化能力が失われた状態。\nこの状態を避けるために学習データとテストデータを分け、\n定期的にテストデータの認識精度も測ることで、\n両方の認識精度が向上していることを確認する必要がある。\u003c/p\u003e\n\u003ch2 id=\"誤差逆伝播backpropagation\"\u003e誤差逆伝播(backpropagation)\u003c/h2\u003e\n\u003cp\u003e微分値によってパラメタを進める方向、量を決めるが、\n微分は一般的に重たい計算のため、高速化するために誤差逆伝播法を用いる。\nこれは各計算を分解、独立化し、chain ruleによって、\n独立した計算それぞれに対する微分を考えていくことで、\n行列計算として微分計算を行えると言う利点がある。\n隠れ層での行列の形状を変化させる計算をAffineレイヤと呼び、\nAffineレイヤを含む、上記の活性化関数それぞれに対し、\n独立して計算済みのレイヤを実装していくことで、\n部品を組み立てるようにニューラルネットワークを実装することができ、\nかつ高速に微分計算を行うことができる。\u003c/p\u003e\n\u003ch4 id=\"勾配確認\"\u003e勾配確認\u003c/h4\u003e\n\u003cp\u003e実装の難しい誤差逆伝播法のバリデーションのため、\n実装の簡単な数値微分の結果と比較すること。\u003c/p\u003e\n\u003ch2 id=\"最適化手法\"\u003e最適化手法\u003c/h2\u003e\n\u003cp\u003eパラメタの更新のことを最適化と呼ぶ。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e確率的勾配降下法(SGD)\u003c/li\u003e\n\u003cli\u003eMomentum\u003c/li\u003e\n\u003cli\u003eAdaGrad\u003c/li\u003e\n\u003cli\u003eAdam\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e上記の4つをこの書籍では取り上げていた。\u003c/p\u003e\n\u003ch5 id=\"sgd\"\u003eSGD\u003c/h5\u003e\n\u003cp\u003e最もシンプルな手法。\n勾配に学習率をかけたものを次のパラメタ更新に用いる。\n欠点として、最小値までの傾斜が等方的でない場合、\nジグザグな動きをすることとなり、学習スピードが遅くなる。\u003c/p\u003e\n\u003ch5 id=\"momentum\"\u003eMomentum\u003c/h5\u003e\n\u003cp\u003e前回の学習スピードを保持することで、\n同じ方向に進むときは加速度的に進み、\nジグザグな動きをするときはSGDと比べて減速するようにした。\u003c/p\u003e\n\u003ch5 id=\"adagrad\"\u003eAdaGrad\u003c/h5\u003e\n\u003cp\u003e学習率を定数ではなく変数にする。\n過去全ての更新量を記憶し、そのぶん学習率を小さくしていく。\n欠点として、学習に長時間かかった場合、学習率が0に近づき、\n学習が進まなくなることが挙げられるが、それを改善したRMSProp\nと言う手法も存在する。\u003c/p\u003e\n\u003ch5 id=\"adam\"\u003eAdam\u003c/h5\u003e\n\u003cp\u003e直感的にはMomentumとAdaGradを組み合わせたようなものらしい\u003c/p\u003e\n\u003ch3 id=\"重みの初期値\"\u003e重みの初期値\u003c/h3\u003e\n\u003ch5 id=\"1を標準偏差としたガウス分布\"\u003e1を標準偏差としたガウス分布\u003c/h5\u003e\n\u003cp\u003e0と1にアクティベーション(各レイヤの出力)が固まることから\n勾配消失が起きているとわかる。\u003c/p\u003e\n\u003ch5 id=\"0001を標準偏差としたガウス分布\"\u003e0.001を標準偏差としたガウス分布\u003c/h5\u003e\n\u003cp\u003e0.5付近に固まるため、勾配消失は怒っていないが、\nその代わり表現力が小さくなっている。\nある値にアクティベーションが集まると、\n単一のレイヤで全てのレイヤを表現できてしまうと言う問題や、\n学習が効率よくいかない問題が挙げられる。\u003c/p\u003e\n\u003ch5 id=\"xavierの初期値\"\u003eXavierの初期値\u003c/h5\u003e\n\u003cp\u003e前層のノードの数に準じて初期値を小さくする手法。\n活性化関数が線形関数(線形関数に近似される関数)の際に用いられる。\u003c/p\u003e\n\u003ch5 id=\"heの初期値\"\u003eHeの初期値\u003c/h5\u003e\n\u003cp\u003eXavierに2倍の広がりをもたせたもの。\n非線形関数に用いられる。\u003c/p\u003e\n\u003ch3 id=\"batch-normalization\"\u003eBatch Normalization\u003c/h3\u003e\n\u003cp\u003eデータを綺麗な分布にならす手法。\nAffineレイヤと活性化関数レイヤの間に\nBatch Normalizationレイヤを入れて使用する。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e学習スピードの増加\u003c/li\u003e\n\u003cli\u003e初期値に対する依存度の減少\u003c/li\u003e\n\u003cli\u003e過学習の抑制\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eなどの効果がある。\u003c/p\u003e\n\u003ch3 id=\"正則化\"\u003e正則化\u003c/h3\u003e\n\u003cp\u003e過学習を抑制するための手法\u003c/p\u003e\n\u003ch5 id=\"weight-decay荷重減衰\"\u003eWeight decay(荷重減衰)\u003c/h5\u003e\n\u003cp\u003e損失関数に重みに準じた量を加算することで、\n大きな重みを持つことにペナルティを課す。\u003c/p\u003e\n\u003ch5 id=\"dropout\"\u003eDropout\u003c/h5\u003e\n\u003cp\u003e確率で、ノードを消去することで何かうまいこと過学習が抑制されるらしい。\u003c/p\u003e\n\u003ch1 id=\"畳み込みニューラルネットワークcnn\"\u003e畳み込みニューラルネットワーク(CNN)\u003c/h1\u003e\n\u003cp\u003e主に画像に用いられるニューラルネットワーク。\n昔のモデル(ここまで考えてきたモデル)では、\nAffineレイヤで前層の出力を全結合していたが、\nその部分をConvolutionレイヤで置き換え、\n必要に応じて、活性化関数適用後の出力にPoolingレイヤを挟むことで\nAffineレイヤの形状無視と言う欠点を補う。\u003c/p\u003e\n\u003ch3 id=\"convolutionレイヤ\"\u003eConvolutionレイヤ\u003c/h3\u003e\n\u003cp\u003e形状を考えるために、入力データに対して、\n\u003cstrong\u003eフィルター(カーネル)\u003c/strong\u003e を用いた結合を行う。\nフィルターは入力データと同じチャンネル数で、任意のサイズを持つ。\nフィルターのサイズと、\n入力データに対する \u003cstrong\u003eパティング\u003c/strong\u003e 、フィルターの \u003cstrong\u003eストライド\u003c/strong\u003e によって\n出力データのサイズが決定する。\n一つのフィルターに対して、出力データのチャンネル数は常に1つのため、\n複数のフィルターを用意して、出力データのチャンネル数を調整する。\u003c/p\u003e\n\u003ch3 id=\"poolingレイヤ\"\u003ePoolingレイヤ\u003c/h3\u003e\n\u003cp\u003eサイズを小さくするための演算。\nある範囲の最も大きな値のみ抽出していくMaxPoolingが画像処理の分野では主流である。\nPoolingレイヤの特徴は以下の3つに代表される。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e学習するパラメータがない\u003c/li\u003e\n\u003cli\u003eチャンネル数は変化しない\u003c/li\u003e\n\u003cli\u003e微小な位置変化に対してロバスト\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"cnnの特徴？\"\u003eCNNの特徴？\u003c/h3\u003e\n\u003cp\u003eフィルターが前半の層では低次元のエッジなどを抽出していくのに対し、\n後半のフィルターは高次元の犬の顔などを抽出し始めるらしい。\nこれは層を多くすることによって、出力までの下準備をそれまでのレイヤで\n丹念にできることに起因するとかしないとか。\u003c/p\u003e\n\u003ch3 id=\"代表的なcnn\"\u003e代表的なCNN\u003c/h3\u003e\n\u003ch5 id=\"lenet\"\u003eLeNet\u003c/h5\u003e\n\u003cp\u003e1998年初めてのCNN？基本的な構造は今使われているものと同じだが、\nPoolingレイヤでMaxPoolingを行なっているわけではないらしいのと、\n活性化関数がSigmoid関数らしい。\u003c/p\u003e\n\u003ch5 id=\"alexnet\"\u003eAlexNet\u003c/h5\u003e\n\u003cp\u003e2012年に彗星のごとくコンペティションに現れ、\n圧倒的な成績でトロフィーと話題をさらっていったAlexNetさんです。\n機械学習ブームの火付け役をしてくれたらしいですね。LeNetと比べると\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e活性化関数にReLU関数を用いる\u003c/li\u003e\n\u003cli\u003eLRNと言う局所的正規化を行う関数を挟む\u003c/li\u003e\n\u003cli\u003eDropoutを使用する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e松尾教授の書籍を読んだ時、うろ覚えですが、確かこのDropoutが\n革新的だったといっていたような気がします。うろ覚えなので突っ込まないでください。\u003c/p\u003e\n\u003ch1 id=\"ディープラーニング\"\u003eディープラーニング\u003c/h1\u003e\n\u003ch3 id=\"層を厚くすると言うこと\"\u003e層を厚くすると言うこと\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e表現力の増加\u003c/li\u003e\n\u003cli\u003e表現するために必要な学習パラメタの減少\u003c/li\u003e\n\u003cli\u003e学習時間は増加\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eこんな感じのメリットデメリットがあるらしい。\n表現力の増加とあるが、実際、MNISTの認識では2層くらいのモデルが\n最も高精度らしく、表現力がどの程度必要なのかも考えなければならない。\nちなみに2015年のクラス分類コンペティションの優勝モデルは\n150層とか言う馬鹿げたレベルのディープさだったそうな。\u003c/p\u003e\n\u003ch3 id=\"有名なネットワーク\"\u003e有名なネットワーク\u003c/h3\u003e\n\u003ch5 id=\"vgg\"\u003eVGG\u003c/h5\u003e\n\u003cp\u003eCNNの基本型らしい。3x3の小さなフィルターでなんども畳み込むそうな。\u003c/p\u003e\n\u003ch5 id=\"googlelenet\"\u003eGoogleLeNet\u003c/h5\u003e\n\u003cp\u003e基本的に層をディープにするといったら、伝播方向っぽいんだけど、\nGoogleさんは横方向にも伸ばしてしまったそうな。\n\u003cstrong\u003eインセプション構造\u003c/strong\u003e と呼ぶらしく、複数のサイズのフィルターで\nたたみ込んでその結果を結合するそうな。\u003c/p\u003e\n\u003ch5 id=\"resnet\"\u003eResNet\u003c/h5\u003e\n\u003cp\u003eGoogleがきてMSが来ないわけがない。\nこれがさっき言ったアホみたいに層を深くした150層ネットワーク。\nレイヤを通した出力とレイヤを通す前の入力の合計をその層の出力とする\nスキップ構造と呼ばれるものを用いることで、\n勾配消失問題を克服して、層をものごっつ厚くできたそうな。\u003c/p\u003e\n\u003ch3 id=\"転移学習\"\u003e転移学習\u003c/h3\u003e\n\u003cp\u003eすでに学習済みのパラメタをそのまま初期値として用いて、\n次の学習を行う手法のこと。少ないデータセットしか手元にない時とかいいらしい。\u003c/p\u003e\n\u003ch3 id=\"最近ディープラーニングで行われていること\"\u003e最近ディープラーニングで行われていること\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e物体検出(物体認識の適用範囲検索と物体認識の結合)\u003c/li\u003e\n\u003cli\u003eセグメンテーション(ピクセルレベルでのクラス分類)\u003c/li\u003e\n\u003cli\u003e画像キャプション生成(CNNとRNNの結合)\u003c/li\u003e\n\u003cli\u003e画像スタイル変換(中間出力とのloss)\u003c/li\u003e\n\u003cli\u003e画像生成(DCGAN)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"強化学習\"\u003e強化学習\u003c/h3\u003e\n\u003cp\u003eエージェント(computer)が環境から得られる報酬を\n最大化するように動いていくのかな？\nゲームとかでやってるらしい。\nパックマンをコンピューターにやらせたらもう人は勝てないらしい。\nとりあえず強化学習にはまた独自のアルゴリズムがあるっぽくて(Q学習？)\nそれとCNNを融合させることでDeep Q-Networkとか言うすごい奴が生まれたらしい。\u003c/p\u003e\n\u003ch1 id=\"まとめ\"\u003eまとめ\u003c/h1\u003e\n\u003cp\u003e特殊な用語がたくさん出てきたので、\nとりあえずこの分野に入るときには一回真面目に入門書を読むべきと感じました。\u003c/p\u003e","ogImage":{"url":"/assets/blog/dynamic-routing/cover.jpg"},"coverImage":"/assets/blog/dynamic-routing/cover.jpg"}},"__N_SSG":true},"page":"/posts/[slug]","query":{"slug":"2017-08-19-intro_deep_learning"},"buildId":"yNrEyh5A0Oyk3eJQw5kY9","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>